import * as z from 'zod';

// Import the Genkit core libraries and plugins.
import { generate } from '@genkit-ai/ai';
import { configureGenkit } from '@genkit-ai/core';
import { firebase } from '@genkit-ai/firebase';
import { gemini15Pro, googleAI } from '@genkit-ai/googleai';

// Import models from the Google AI plugin. The Google AI API provides access to
// several generative models. Here, we import Gemini 1.5 Flash.
import { gemini15Flash } from '@genkit-ai/googleai';

// From the Firebase plugin, import the functions needed to deploy flows using
// Cloud Functions.
import { firebaseAuth } from '@genkit-ai/firebase/auth';
import { onFlow } from '@genkit-ai/firebase/functions';
import { Part } from '@genkit-ai/ai/retriever';

configureGenkit({
  plugins: [
    // Load the Firebase plugin, which provides integrations with several
    // Firebase services.
    firebase(),
    // Load the Google AI plugin. You can optionally specify your API key
    // by passing in a config object; if you don't, the Google AI plugin uses
    // the value from the GOOGLE_GENAI_API_KEY environment variable, which is
    // the recommended practice.
    googleAI(),
  ],
  // Log debug output to tbe console.
  logLevel: 'debug',
  // Perform OpenTelemetry instrumentation and enable trace collection.
  enableTracingAndMetrics: true,
});

// Define a simple flow that prompts an LLM to generate menu suggestions.
export const menuSuggestionFlow = onFlow(
  {
    name: 'menuSuggestionFlow',
    inputSchema: z.string(),
    outputSchema: z.string(),
    authPolicy: firebaseAuth((user) => {
      // By default, the firebaseAuth policy requires that all requests have an
      // `Authorization: Bearer` header containing the user's Firebase
      // Authentication ID token. All other requests are rejected with error
      // 403. If your app client uses the Firebase Cloud Functions callable
      // functions feature, the library automatically attaches this header to
      // requests.
      // You should also set additional policy requirements as appropriate for
      // your app. For example:
      // if (!user.email_verified) {
      //   throw new Error("Verified email required to run flow");
      // }
    }),
  },
  async (subject) => {
    // Construct a request and send it to the model API.
    const prompt = `Suggest an item for the menu of a ${subject} themed restaurant`;
    const llmResponse = await generate({
      model: gemini15Flash,
      prompt: prompt,
      config: {
        temperature: 1,
      },
    });

    // Handle the response from the model API. In this sample, we just
    // convert it to a string, but more complicated flows might coerce the
    // response into structured output or chain the response into another
    // LLM call, etc.
    return llmResponse.text();
  }
);

export const generateAlbumDescription = onFlow(
  {
    name: 'generateAlbumDescription',
    inputSchema: z.object({
      photoUrls: z.array(
        z.object({ httpUrl: z.string(), contentType: z.string().optional() })
      ),
      voice: z.string().optional(),
    }),
    outputSchema: z.string(),
    authPolicy: firebaseAuth((user) => {}),
  },
  async (subject) => {
    let promptText =
      'Write a description of the album comprised of the these photos';

    if (subject.voice) {
      promptText += ` in the voice of ${subject.voice}`;
    }

    const thePrompt = [
      {
        text: promptText,
      },
    ] as Part[];

    subject.photoUrls.forEach((u) => {
      thePrompt.push({
        media: {
          url: u.httpUrl,
          contentType: u.contentType,
        },
      });
    });

    const response = await generate({
      model: gemini15Pro,
      config: {
        temperature: 0.7, // Adjust temperature for creativity
      },
      prompt: thePrompt,
    });

    return response.text();
  }
);
